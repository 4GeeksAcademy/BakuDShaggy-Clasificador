{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ======================\n",
                "# IMPORTAR LIBRERÍAS\n",
                "# ======================\n",
                "# CONFIGURACIÓN INICIAL\n",
                "# ======================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "\n",
                "# Configurar rutas\n",
                "RAW_PATH = \"../data/raw/train/train/\"\n",
                "INTERIM_PATH = \"data/interim/full/\"\n",
                "MODEL_PATH = \"models/\"\n",
                "REPORT_PATH = \"reports/\"\n",
                "\n",
                "# Crear directorios necesarios\n",
                "os.makedirs(INTERIM_PATH, exist_ok=True)\n",
                "os.makedirs(os.path.join(INTERIM_PATH, \"cats\"), exist_ok=True)\n",
                "os.makedirs(os.path.join(INTERIM_PATH, \"dogs\"), exist_ok=True)\n",
                "os.makedirs(os.path.join(INTERIM_PATH, \"train/cats\"), exist_ok=True)\n",
                "os.makedirs(os.path.join(INTERIM_PATH, \"train/dogs\"), exist_ok=True)\n",
                "os.makedirs(os.path.join(INTERIM_PATH, \"validation/cats\"), exist_ok=True)\n",
                "os.makedirs(os.path.join(INTERIM_PATH, \"validation/dogs\"), exist_ok=True)\n",
                "os.makedirs(MODEL_PATH, exist_ok=True)\n",
                "os.makedirs(REPORT_PATH, exist_ok=True)\n",
                "\n",
                "# ======================\n",
                "# FUNCIONES AUXILIARES\n",
                "# ======================\n",
                "def process_images(source_path, dest_path, target_size=(200, 200)):\n",
                "    \"\"\"Redimensiona imágenes y las organiza en carpetas por clase\"\"\"\n",
                "    for filename in os.listdir(source_path):\n",
                "        if filename.endswith('.jpg'):\n",
                "            img = cv2.imread(os.path.join(source_path, filename))\n",
                "            if img is not None:\n",
                "                img = cv2.resize(img, target_size)\n",
                "                class_folder = 'cats' if filename.startswith('cat') else 'dogs'\n",
                "                cv2.imwrite(os.path.join(dest_path, class_folder, filename), img)\n",
                "\n",
                "def split_dataset(base_path):\n",
                "    \"\"\"Divide el dataset en entrenamiento y validación\"\"\"\n",
                "    for animal in ['cats', 'dogs']:\n",
                "        animal_path = os.path.join(base_path, animal)\n",
                "        if not os.path.exists(animal_path):\n",
                "            os.makedirs(animal_path, exist_ok=True)\n",
                "        files = [f for f in os.listdir(animal_path) if f.endswith('.jpg')]\n",
                "        train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n",
                "        \n",
                "        # Mover a entrenamiento\n",
                "        for file in train_files:\n",
                "            src = os.path.join(animal_path, file)\n",
                "            dst = os.path.join(base_path, 'train', animal, file)\n",
                "            shutil.copy(src, dst)\n",
                "        \n",
                "        # Mover a validación\n",
                "        for file in val_files:\n",
                "            src = os.path.join(animal_path, file)\n",
                "            dst = os.path.join(base_path, 'validation', animal, file)\n",
                "            shutil.copy(src, dst)\n",
                "\n",
                "def plot_class_distribution(train_path, val_path):\n",
                "    \"\"\"Muestra la distribución de clases\"\"\"\n",
                "    train_cats = len(os.listdir(os.path.join(train_path, \"cats\")))\n",
                "    train_dogs = len(os.listdir(os.path.join(train_path, \"dogs\")))\n",
                "    val_cats = len(os.listdir(os.path.join(val_path, \"cats\")))\n",
                "    val_dogs = len(os.listdir(os.path.join(val_path, \"dogs\")))\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.barplot(\n",
                "        x=['Gatos (Train)', 'Perros (Train)', 'Gatos (Val)', 'Perros (Val)'],\n",
                "        y=[train_cats, train_dogs, val_cats, val_dogs]\n",
                "    )\n",
                "    plt.title(\"Distribución de Clases\")\n",
                "    plt.ylabel(\"Cantidad\")\n",
                "    plt.savefig(os.path.join(REPORT_PATH, \"class_distribution.png\"))\n",
                "    plt.show()\n",
                "\n",
                "def plot_image_samples(path, title, num_samples=5):\n",
                "    \"\"\"Muestra muestras de imágenes\"\"\"\n",
                "    files = [f for f in os.listdir(path) if f.endswith('.jpg')][:num_samples]\n",
                "    \n",
                "    plt.figure(figsize=(15, 3))\n",
                "    plt.suptitle(title, fontsize=16)\n",
                "    \n",
                "    for i, filename in enumerate(files):\n",
                "        img = plt.imread(os.path.join(path, filename))\n",
                "        plt.subplot(1, num_samples, i+1)\n",
                "        plt.imshow(img)\n",
                "        plt.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(REPORT_PATH, f\"{title.lower().replace(' ', '_')}_samples.png\"))\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ======================\n",
                "# PREPARACIÓN DE DATOS\n",
                "# ======================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Procesando imágenes...\n",
                        "Dividiendo dataset...\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m process_images(RAW_PATH, INTERIM_PATH, target_size=(\u001b[32m200\u001b[39m, \u001b[32m200\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDividiendo dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43msplit_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERIM_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Visualizar distribución de clases\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVisualizando distribución de clases...\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36msplit_dataset\u001b[39m\u001b[34m(base_path)\u001b[39m\n\u001b[32m     49\u001b[39m     os.makedirs(animal_path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     50\u001b[39m files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(animal_path) \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m train_files, val_files = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Mover a entrenamiento\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m train_files:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
                        "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
                    ]
                }
            ],
            "source": [
                "print(\"Procesando imágenes...\")\n",
                "process_images(RAW_PATH, INTERIM_PATH, target_size=(200, 200))\n",
                "\n",
                "print(\"Dividiendo dataset...\")\n",
                "split_dataset(INTERIM_PATH)\n",
                "\n",
                "# Visualizar distribución de clases\n",
                "print(\"Visualizando distribución de clases...\")\n",
                "plot_class_distribution(\n",
                "    train_path=os.path.join(INTERIM_PATH, \"train\"),\n",
                "    val_path=os.path.join(INTERIM_PATH, \"validation\")\n",
                ")\n",
                "\n",
                "# Visualizar muestras\n",
                "print(\"Visualizando muestras de gatos...\")\n",
                "plot_image_samples(\n",
                "    path=os.path.join(INTERIM_PATH, \"train/cats\"),\n",
                "    title=\"Gatos (Entrenamiento)\"\n",
                ")\n",
                "\n",
                "print(\"Visualizando muestras de perros...\")\n",
                "plot_image_samples(\n",
                "    path=os.path.join(INTERIM_PATH, \"train/dogs\"),\n",
                "    title=\"Perros (Entrenamiento)\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ======================\n",
                "# GENERADORES DE DATOS\n",
                "# ======================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Aumento de datos para entrenamiento\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=20,\n",
                "    width_shift_range=0.2,\n",
                "    height_shift_range=0.2,\n",
                "    shear_range=0.2,\n",
                "    zoom_range=0.2,\n",
                "    horizontal_flip=True,\n",
                "    fill_mode='nearest'\n",
                ")\n",
                "\n",
                "# Solo reescalar para validación\n",
                "val_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "# Generadores\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    os.path.join(INTERIM_PATH, \"train\"),\n",
                "    target_size=(200, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='categorical'\n",
                ")\n",
                "\n",
                "validation_generator = val_datagen.flow_from_directory(\n",
                "    os.path.join(INTERIM_PATH, \"validation\"),\n",
                "    target_size=(200, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='categorical'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ======================\n",
                "# CONSTRUCCIÓN DEL MODELO\n",
                "# ======================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Versión simplificada de VGG para estudiantes\n",
                "model = Sequential([\n",
                "    # Bloque 1\n",
                "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(200, 200, 3)),\n",
                "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
                "    MaxPool2D((2, 2)),\n",
                "    Dropout(0.25),\n",
                "    \n",
                "    # Bloque 2\n",
                "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
                "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
                "    MaxPool2D((2, 2)),\n",
                "    Dropout(0.25),\n",
                "    \n",
                "    # Bloque 3\n",
                "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
                "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
                "    MaxPool2D((2, 2)),\n",
                "    Dropout(0.25),\n",
                "    \n",
                "    # Clasificador\n",
                "    Flatten(),\n",
                "    Dense(512, activation='relu'),\n",
                "    Dropout(0.5),\n",
                "    Dense(2, activation='softmax')\n",
                "])\n",
                "\n",
                "model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "model.summary()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ======================\n",
                "# ENTRENAMIENTO\n",
                "# ======================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks\n",
                "checkpoint = ModelCheckpoint(\n",
                "    os.path.join(MODEL_PATH, 'best_model.h5'),\n",
                "    monitor='val_accuracy',\n",
                "    save_best_only=True,\n",
                "    mode='max',\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "early_stop = EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=5,\n",
                "    restore_best_weights=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "# Entrenamiento\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    steps_per_epoch=len(train_generator),\n",
                "    epochs=20,\n",
                "    validation_data=validation_generator,\n",
                "    validation_steps=len(validation_generator),\n",
                "    callbacks=[checkpoint, early_stop]\n",
                ")\n",
                "\n",
                "# Guardar modelo final\n",
                "model.save(os.path.join(MODEL_PATH, 'final_model.h5'))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ======================\n",
                "# EVALUACIÓN Y RESULTADOS\n",
                "# ======================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'plt' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Gráficas de entrenamiento\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Precisión\u001b[39;00m\n\u001b[32m      5\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n",
                        "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
                    ]
                }
            ],
            "source": [
                "# Gráficas de entrenamiento\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "# Precisión\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
                "plt.plot(history.history['val_accuracy'], label='Validación')\n",
                "plt.title('Precisión del Modelo')\n",
                "plt.ylabel('Precisión')\n",
                "plt.xlabel('Época')\n",
                "plt.legend()\n",
                "\n",
                "# Pérdida\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history.history['loss'], label='Entrenamiento')\n",
                "plt.plot(history.history['val_loss'], label='Validación')\n",
                "plt.title('Pérdida del Modelo')\n",
                "plt.ylabel('Pérdida')\n",
                "plt.xlabel('Época')\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(REPORT_PATH, 'training_history.png'))\n",
                "plt.show()\n",
                "\n",
                "# Evaluación final\n",
                "test_loss, test_acc = model.evaluate(validation_generator)\n",
                "print(f'\\nPrecisión final en validación: {test_acc:.4f}')\n",
                "print(f'Pérdida final en validación: {test_loss:.4f}')\n",
                "\n",
                "# Matriz de confusión\n",
                "y_true = []\n",
                "y_pred = []\n",
                "\n",
                "# Predecir todo el conjunto de validación\n",
                "for i in range(len(validation_generator)):\n",
                "    X, y = validation_generator[i]\n",
                "    y_true.extend(np.argmax(y, axis=1))\n",
                "    y_pred.extend(np.argmax(model.predict(X), axis=1))\n",
                "\n",
                "# Reporte de clasificación\n",
                "print(\"\\nReporte de Clasificación:\")\n",
                "print(classification_report(y_true, y_pred, target_names=['Gatos', 'Perros']))\n",
                "\n",
                "# Matriz de confusión\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['Gatos', 'Perros'], \n",
                "            yticklabels=['Gatos', 'Perros'])\n",
                "plt.title('Matriz de Confusión')\n",
                "plt.ylabel('Verdadero')\n",
                "plt.xlabel('Predicción')\n",
                "plt.savefig(os.path.join(REPORT_PATH, 'confusion_matrix.png'))\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

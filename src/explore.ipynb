{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'src'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_directory_structure\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_image_samples, plot_class_distribution\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
                    ]
                }
            ],
            "source": [
                "# Your code here\n",
                "import os\n",
                "import shutil\n",
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from src.utils import create_directory_structure\n",
                "from src.utils import plot_image_samples, plot_class_distribution\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "\n",
                "# 1. Configurar estructura de directorios\n",
                "RAW_PATH = \"../data/raw/train/\"\n",
                "INTERIM_PATH = \"../data/interim/\"\n",
                "create_directory_structure(INTERIM_PATH)\n",
                "\n",
                "# 2. Procesar imágenes (redimensionar a 200x200)\n",
                "def process_images(source_path, dest_path, target_size=(200, 200)):\n",
                "    for filename in os.listdir(source_path):\n",
                "        img = cv2.imread(os.path.join(source_path, filename))\n",
                "        if img is not None:\n",
                "            img = cv2.resize(img, target_size)\n",
                "            class_folder = 'cats' if 'cat' in filename else 'dogs'\n",
                "            cv2.imwrite(os.path.join(dest_path, class_folder, filename), img)\n",
                "\n",
                "# 3. Dividir en entrenamiento/validación (80/20)\n",
                "def split_dataset(base_path):\n",
                "    for animal in ['cats', 'dogs']:\n",
                "        files = os.listdir(os.path.join(base_path, animal))\n",
                "        train, val = train_test_split(files, test_size=0.2, random_state=42)\n",
                "        \n",
                "        for file in train:\n",
                "            src = os.path.join(base_path, animal, file)\n",
                "            dst = os.path.join(base_path, 'train', animal, file)\n",
                "            shutil.move(src, dst)\n",
                "        \n",
                "        for file in val:\n",
                "            src = os.path.join(base_path, animal, file)\n",
                "            dst = os.path.join(base_path, 'validation', animal, file)\n",
                "            shutil.move(src, dst)\n",
                "\n",
                "# Ejecutar procesamiento\n",
                "process_images(RAW_PATH, os.path.join(INTERIM_PATH, \"full\"))\n",
                "split_dataset(os.path.join(INTERIM_PATH, \"full\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Distribución de clases\n",
                "plot_class_distribution(\n",
                "    train_path=\"../data/interim/full/train\",\n",
                "    val_path=\"../data/interim/full/validation\"\n",
                ")\n",
                "\n",
                "# 2. Muestras visuales\n",
                "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
                "plot_image_samples(\"../data/interim/full/train/cats\", ax[0], 'Cats (Train)')\n",
                "plot_image_samples(\"../data/interim/full/train/dogs\", ax[1], 'Dogs (Train)')\n",
                "plt.tight_layout()\n",
                "plt.savefig(\"../reports/sample_images.png\")\n",
                "plt.show()\n",
                "\n",
                "# 3. Estadísticas de tamaño (originales)\n",
                "def check_original_sizes(path):\n",
                "    sizes = []\n",
                "    for filename in os.listdir(path):\n",
                "        img = cv2.imread(os.path.join(path, filename))\n",
                "        if img is not None:\n",
                "            sizes.append(img.shape[:2])\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.scatterplot(x=[w for h,w in sizes], y=[h for h,w in sizes])\n",
                "    plt.title(\"Original Image Dimensions\")\n",
                "    plt.xlabel(\"Width\")\n",
                "    plt.ylabel(\"Height\")\n",
                "    plt.savefig(\"../reports/image_dimensions.png\")\n",
                "\n",
                "check_original_sizes(RAW_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_directory_structure(base_path):\n",
                "    os.makedirs(os.path.join(base_path, \"full\", \"cats\"), exist_ok=True)\n",
                "    os.makedirs(os.path.join(base_path, \"full\", \"dogs\"), exist_ok=True)\n",
                "    os.makedirs(os.path.join(base_path, \"full\", \"train\", \"cats\"), exist_ok=True)\n",
                "    os.makedirs(os.path.join(base_path, \"full\", \"train\", \"dogs\"), exist_ok=True)\n",
                "    os.makedirs(os.path.join(base_path, \"full\", \"validation\", \"cats\"), exist_ok=True)\n",
                "    os.makedirs(os.path.join(base_path, \"full\", \"validation\", \"dogs\"), exist_ok=True)\n",
                "\n",
                "def plot_class_distribution(train_path, val_path):\n",
                "    train_cats = len(os.listdir(os.path.join(train_path, \"cats\")))\n",
                "    train_dogs = len(os.listdir(os.path.join(train_path, \"dogs\")))\n",
                "    val_cats = len(os.listdir(os.path.join(val_path, \"cats\")))\n",
                "    val_dogs = len(os.listdir(os.path.join(val_path, \"dogs\")))\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.barplot(\n",
                "        x=['Train Cats', 'Train Dogs', 'Val Cats', 'Val Dogs'],\n",
                "        y=[train_cats, train_dogs, val_cats, val_dogs]\n",
                "    )\n",
                "    plt.title(\"Class Distribution\")\n",
                "    plt.ylabel(\"Count\")\n",
                "    plt.savefig(\"../reports/class_distribution.png\")\n",
                "    plt.show()\n",
                "\n",
                "def plot_image_samples(path, axes, title):\n",
                "    files = [f for f in os.listdir(path) if f.endswith('.jpg')][:5]\n",
                "    for i, filename in enumerate(files):\n",
                "        img = mpimg.imread(os.path.join(path, filename))\n",
                "        axes[i].imshow(img)\n",
                "        axes[i].axis('off')\n",
                "    axes[0].set_title(title, fontsize=12)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Generadores de datos\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=20,\n",
                "    zoom_range=0.2,\n",
                "    horizontal_flip=True\n",
                ")\n",
                "\n",
                "val_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    \"../data/interim/full/train\",\n",
                "    target_size=(200, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='categorical'\n",
                ")\n",
                "\n",
                "validation_generator = val_datagen.flow_from_directory(\n",
                "    \"../data/interim/full/validation\",\n",
                "    target_size=(200, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='categorical'\n",
                ")\n",
                "\n",
                "# 2. Construcción del modelo (ajustado a 200x200)\n",
                "model = Sequential([\n",
                "    Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(200,200,3)),\n",
                "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
                "    MaxPool2D(2,2),\n",
                "    \n",
                "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
                "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
                "    MaxPool2D(2,2),\n",
                "    \n",
                "    # ... continuar con arquitectura similar ajustando tamaños ...\n",
                "    \n",
                "    Flatten(),\n",
                "    Dense(1024, activation='relu'),\n",
                "    Dense(512, activation='relu'),\n",
                "    Dense(2, activation='softmax')\n",
                "])\n",
                "\n",
                "model.compile(optimizer='adam',\n",
                "              loss='categorical_crossentropy',\n",
                "              metrics=['accuracy'])\n",
                "\n",
                "# 3. Callbacks y entrenamiento\n",
                "checkpoint = ModelCheckpoint(\n",
                "    '../models/best_model.h5',\n",
                "    monitor='val_accuracy',\n",
                "    save_best_only=True,\n",
                "    mode='max'\n",
                ")\n",
                "\n",
                "early_stop = EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=5,\n",
                "    restore_best_weights=True\n",
                ")\n",
                "\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    epochs=30,\n",
                "    validation_data=validation_generator,\n",
                "    callbacks=[checkpoint, early_stop]\n",
                ")\n",
                "\n",
                "# Guardar modelo final\n",
                "model.save('../models/final_model.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Gráficas de precisión/pérdida\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
                "plt.title('Training Accuracy')\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history.history['loss'], label='Train Loss')\n",
                "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
                "plt.title('Training Loss')\n",
                "plt.legend()\n",
                "\n",
                "plt.savefig('../reports/training_history.png')\n",
                "plt.show()\n",
                "\n",
                "# 2. Evaluación final\n",
                "test_loss, test_acc = model.evaluate(validation_generator)\n",
                "print(f'\\nTest accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}')\n",
                "\n",
                "# 3. Matriz de confusión\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "import numpy as np\n",
                "\n",
                "y_true = []\n",
                "y_pred = []\n",
                "\n",
                "for i in range(len(validation_generator)):\n",
                "    X, y = validation_generator[i]\n",
                "    y_true.extend(np.argmax(y, axis=1))\n",
                "    y_pred.extend(np.argmax(model.predict(X), axis=1))\n",
                "\n",
                "print(classification_report(y_true, y_pred))\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.savefig('../reports/confusion_matrix.png') "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
